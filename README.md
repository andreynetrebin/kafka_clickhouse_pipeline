# Интеграция Kafka с ClickHouse

Данный проект демонстрирует современный подход к построению потоковых ETL-конвейеров с использованием Apache Kafka в качестве брокера сообщений и ClickHouse как высокопроизводительной колоночной СУБД для аналитики.

## Содержание

- [Цель проекта](#цель-проекта)
- [1. Базовая интеграция Kafka + ClickHouse](#1.-Базовая-интеграция-Kafka-+-ClickHouse)
- [1.1. Архитектура решения](#1.1.-Архитектура-решения)
- [1.2. Структура данных](#1.2.-Структура-данных)
- [1.3. Быстрый старт](#1.3.-Быстрый-старт)
- [1.4. Механика работы](#1.4.-Механика-работы)
- [1.5 Ключевые выводы](#1.5-Ключевые-выводы)
- [2. Анализ применимости Kafka для обновлений данных](#2.-Анализ-применимости-Kafka-для-обновлений-данных)
- [2.1. Проблематика работы с обновлениями в ClickHouse](#2.1.-Проблематика-работы-с-обновлениями-в-ClickHouse)
- [2.2. Архитектурные решения с Kafka](#2.2.-Архитектурные-решения-с-Kafka)
- [2.3. Батч-обработка для больших объемов](#2.3.-Батч-обработка-для-больших-объемов)
- [2.4. Практические сценарии применения](#2.4.-Практические-сценарии-применения)
- [2.5. Ключевые выводы](#2.5.-Ключевые-выводы)


## Цель проекта

1. Реализовать на практике:
Базовую интеграцию Kafka + ClickHouse с разветыванием в Docker-окружении:
- Real-time потребление данных из Kafka топиков
- Автоматическую трансформацию данных с помощью Materialized Views
- Создание оптимизированных хранилищ для аналитических запросов

2. Провести анализ применимости Kafka для сценариев:
- Частых обновлений данных (цены, инвентарь)
- Очень больших объемов (миллионы изменений/день)
- CDC-архитектур с батч-обработкой


## 1. Базовая интеграция Kafka + ClickHouse    

## 1.1. Архитектура решения
Основной поток данных
```text
[Data Generator] → [Kafka Topics] → [Kafka Engine Tables] → [Materialized Views] → [Target Tables]
```
Детальная схема
```text
Python App → Kafka (sales topic) → sales_kafka (Kafka Engine) → sales_mv (MV) → sales (MergeTree)
Python App → Kafka (warehouse topic) → warehouse_kafka (Kafka Engine) → stock_movements_mv (MV) → stock_movements (MergeTree)
```
## 1.2. Структура данных
Топики Kafka:
  - sales - данные о продажах (70% трафика)
  - warehouse - движения товаров на складе (30% трафика)

Таблицы с движком Kafka (приемники):
  - sales_kafka - приемник для топика sales
  - warehouse_kafka - приемник для топика warehouse

Материализованные представления для трансформации данных от таблиц приемников в целевые:
  - sales_mv  - трансформация для продаж
  - stock_movements_mv  - трансформация для движений склада

Целевые таблицы ClickHouse
  - sales - финальные данные продаж (MergeTree)
  - stock_movements - движения товаров (MergeTree)

## 1.3. Быстрый старт
Предварительные требования
  - Docker
  - Docker Compose
  - 4+ Гб ОЗУ

### Запуск проекта
  ```bash
# Клонирование репозитория
git clone https://github.com/andreynetrebin/kafka_clickhouse_pipeline/
cd kafka_clickhouse_pipeline

# Запуск всех сервисов
docker-compose up -d

# Проверка статуса сервисов
docker-compose ps -a

# Просмотр логов генератора данных
docker-compose logs data-generator -f

# Просмотр логов ClickHouse
docker-compose logs clickhouse -f
  ```

## 1.4. Механика работы
1. Генерация данных с интенсивностью с 0.5-1.5 секунды между сообщениями
   ```python
    # Python-приложение генерирует тестовые данные в json-формате
    # и отправляет в соответствующие топики Kafka
    producer.send('sales', sale_data)
    producer.send('warehouse', movement_data)
   ```
2. Потребление из Kafka
  ```sql
  -- Таблицы Kafka Engine подключаются к топикам
  CREATE TABLE sales_kafka (...) ENGINE = Kafka(
      kafka_broker_list = 'kafka:29092',
      kafka_topic_list = 'sales',
      kafka_group_name = 'clickhouse_sales_consumer',
      kafka_format = 'JSONEachRow',
      kafka_group_name = 'clickhouse_consumer'
  );
  ```  
3. Трансформация через материализованные представления (Materialized Views)
   ```sql
    -- MV автоматически преобразуют и переносят данные
    CREATE MATERIALIZED VIEW sales_mv TO sales AS
    SELECT 
        event_id,
        parseDateTimeBestEffort(event_time) as event_time,
        -- ... преобразования полей
    FROM sales_kafka;
   ```
4.  Хранение в оптимизированных таблицах
   ```sql
    -- Данные хранятся в MergeTree с партицированием по месяцам и сортировкой
    CREATE TABLE sales (
        -- ...
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(event_time)
    ORDER BY (event_time, product_id);
   ```

## 1.5. Ключевые выводы по базовой реализации
✅ Что успешно реализовано:
  - Рабочий ETL-конвейер в Docker-окружении
  - Real-time потребление данных из Kafka топиков
  - Автоматическая трансформация через Materialized Views
  - Готовое решение для аналитических сценариев

Идеальные сценарии для данной архитектуры:
```sql
-- Данные преимущественно append-only
-- Высокие объемы записи (50-100K+ сообщений/сек)
-- Требуется отказоустойчивость и буферизация нагрузки
-- Основное назначение - аналитика и мониторинг
```
Когда рассмотреть другие подходы:
```sql
-- Частые обновления данных (использовать CDC + батч-обработку)
-- Критичен строгий порядок событий 
-- Требуются ACID транзакции
-- Приоритет простоте над масштабируемостью
```
Данная базовая архитектура отлично подходит для 80% аналитических сценариев, обеспечивая высокую производительность и надежность при минимальной сложности реализации.

## 2. Анализ применимости Kafka для сценариев с частыми обновлениями данных


## 2.1. Проблематика работы с обновлениями в ClickHouse
Основное ограничение:
```sql
-- НЕЭФФЕКТИВНО: Каждое обновление перезаписывает целые гранулы данных
UPDATE products SET price = 150 WHERE product_id = 123;
```
Сравнение подходов:
Метод	Производительность	Нагрузка CPU	Поддержка объемов
Точечные UPDATE	~1,000 ops/sec	100%	Низкая
Батч-обработка	~100,000 ops/sec	10-15%	Высокая

## 2.2. Архитектурные решения с Kafka

CDC (Change Data Capture) подход
```
[OLTP БД: PostgreSQL/MySQL] → [Debezium CDC] → [Kafka] → [ClickHouse ReplacingMergeTree]
```
Преимущества Kafka в CDC:
  
  - ✅ Буферизация пиков - обработка всплесков обновлений
  - ✅ Гарантированный порядок - сохранение последовательности изменений
  - ✅ Отказоустойчивость - повторная обработка после сбоев
  - ✅ Масштабируемость - партиционирование по ключам обновления

Реализация в ClickHouse
```sql
-- Таблица для приема изменений
CREATE TABLE products_changes (
    product_id UInt64,
    new_price Decimal32(2),
    operation Enum8('insert' = 1, 'update' = 2, 'delete' = 3),
    change_time DateTime,
    _version UInt64 MATERIALIZED toUnixTimestamp(change_time)
) ENGINE = ReplacingMergeTree(change_time)
ORDER BY (product_id, _version);

-- Материализованное представление
CREATE MATERIALIZED VIEW products_mv TO products_changes AS
SELECT * FROM kafka_cdc_topic;
```
## 2.3. Батч-обработка для больших объемов

Архитектура батч-обработки:
```text
[OLTP БД] → [Debezium] → [Kafka] → [Staging Table] → [Батч-MERGE] → [Final Table]
```
Метрики для 10M+ записей:
  - 📊 Объем данных: 2-4 GB изменений в день
  - ⚡ Время обработки: 10-30 секунд на час данных
  - ⏱️ Задержка актуальности: 5-60 минут
  - 💾 Нагрузка CPU: 5-10% во время батчей

Ключевые преимущества батч-обработки:
   - 🚀 Высокая производительность - 100x эффективнее точечных UPDATE
   - 📈 Масштабируемость - поддержка миллионов изменений в день
   - 💡 Эффективность - минимальная нагрузка на ClickHouse
   - 🕰️ Историчность - полное сохранение истории изменений

## 2.4. Практические сценарии применения
Идеально для:
   - 🏪 Каталоги товаров - частые обновления цен и наличия
   - 📦 Inventory management - управление остатками
   - 📚 Справочники - часто изменяемые данные
   - 📊 Конфигурации - динамические настройки систем

Рекомендуемые паттерны:
```sql
-- Ежечасное применение изменений
INSERT INTO products_final
SELECT 
    product_id,
    argMax(new_price, change_time) as current_price
FROM products_changes
WHERE change_time > now() - interval 1 hour
GROUP BY product_id;
```

## 2.5. Ключевые выводы

Kafka + CDC - оптимальное решение для:
   - 🔄 Реализации частых обновлений в ClickHouse
   - 📊 Обработки больших объемов изменений
   - 🛡️ Обеспечения отказоустойчивости и надежности
   - ⚡ Поддержки near real-time актуальности данных

Батч-обработка является единственным эффективным способом работы с частыми обновлениями в ClickHouse на больших объемах данных, обеспечивая производительность и масштабируемость.

Рекомендация: Использовать связку Debezium + Kafka + батч-обработка для сценариев, требующих частых обновлений данных в аналитических хранилищах на основе ClickHouse.
